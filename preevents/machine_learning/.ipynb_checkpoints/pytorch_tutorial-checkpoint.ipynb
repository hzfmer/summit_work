{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two_layer_net_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, D_in, H, D_out: Batch size, input size, hidden dimension, output size\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 444.162338574896\n",
      "10 339.4491447497711\n",
      "20 260.5573131661747\n",
      "30 200.84408546905314\n",
      "40 155.4246697993538\n",
      "50 120.727625814796\n",
      "60 94.09796537384167\n",
      "70 73.59368587452764\n",
      "80 57.74737518675988\n",
      "90 45.45705604372796\n",
      "100 35.8958129858751\n",
      "110 28.43278478870279\n",
      "120 22.58926021828308\n",
      "130 17.999847871709832\n",
      "140 14.384989721335405\n",
      "150 11.529790380768448\n",
      "160 9.268523921506063\n",
      "170 7.473224531996838\n",
      "180 6.043914094851909\n",
      "190 4.902807023055179\n"
     ]
    }
   ],
   "source": [
    "for t in range(200):\n",
    "    # Forward pass\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 10 == 0:\n",
    "        print(t, loss)\n",
    "    \n",
    "    # Backpropagation \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[grad_h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    \n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29305188.95507461\n",
      "1 26276731.701896057\n",
      "2 27243752.910063103\n",
      "3 27838833.546051547\n",
      "4 25474877.425890535\n",
      "5 19539789.612616226\n",
      "6 12681380.74416888\n",
      "7 7235302.364886772\n",
      "8 3974295.6531337025\n",
      "9 2256363.859266419\n",
      "10 1403104.8554106166\n",
      "11 965682.5383940553\n",
      "12 724627.4389913494\n",
      "13 576987.6932025069\n",
      "14 476659.15254027396\n",
      "15 402564.63135418494\n",
      "16 344596.14045215264\n",
      "17 297640.4777392037\n",
      "18 258832.51466188833\n",
      "19 226197.17299713078\n",
      "20 198550.61703469674\n",
      "21 174950.02013575\n",
      "22 154645.288724882\n",
      "23 137068.5821367699\n",
      "24 121854.74722284309\n",
      "25 108590.89877581003\n",
      "26 96996.50702471253\n",
      "27 86830.13368889628\n",
      "28 77897.33071329104\n",
      "29 70028.12890982475\n",
      "30 63076.8804853361\n",
      "31 56918.902993147356\n",
      "32 51449.65028956093\n",
      "33 46591.33188773788\n",
      "34 42261.10673215464\n",
      "35 38388.73387519525\n",
      "36 34918.95486032148\n",
      "37 31807.138522113702\n",
      "38 29011.37364722824\n",
      "39 26494.644434100384\n",
      "40 24225.73304538243\n",
      "41 22176.944295375015\n",
      "42 20327.518983920898\n",
      "43 18653.148392693853\n",
      "44 17134.61846406529\n",
      "45 15756.60632811649\n",
      "46 14503.254495369889\n",
      "47 13362.001490463317\n",
      "48 12322.009809274303\n",
      "49 11373.284548542753\n",
      "50 10506.415883729338\n",
      "51 9713.938207815074\n",
      "52 8988.21586135538\n",
      "53 8323.401715130703\n",
      "54 7713.533998984948\n",
      "55 7153.438717227586\n",
      "56 6638.941201931434\n",
      "57 6165.676200602534\n",
      "58 5729.980144980801\n",
      "59 5328.542355357571\n",
      "60 4958.621447738811\n",
      "61 4617.292506564251\n",
      "62 4302.184785579451\n",
      "63 4010.945389406036\n",
      "64 3741.3813354014574\n",
      "65 3491.762645187644\n",
      "66 3260.572743363432\n",
      "67 3046.4815990413204\n",
      "68 2848.044063445962\n",
      "69 2663.924292002983\n",
      "70 2492.876867950455\n",
      "71 2333.9326792881325\n",
      "72 2186.1000979305945\n",
      "73 2048.563563014945\n",
      "74 1920.4590073387496\n",
      "75 1801.127094422478\n",
      "76 1689.8820614171748\n",
      "77 1586.1391120790463\n",
      "78 1489.3740745135074\n",
      "79 1399.039696872689\n",
      "80 1314.6549355788802\n",
      "81 1235.7898273185237\n",
      "82 1162.0786299541683\n",
      "83 1093.1290747476219\n",
      "84 1028.6280843048773\n",
      "85 968.2282477967572\n",
      "86 911.652593424406\n",
      "87 858.6610210644782\n",
      "88 808.9965195106276\n",
      "89 762.4159325410235\n",
      "90 718.7341487921332\n",
      "91 677.7380789528748\n",
      "92 639.2511102363999\n",
      "93 603.1100301681063\n",
      "94 569.1689112021435\n",
      "95 537.2858841054997\n",
      "96 507.31543189186806\n",
      "97 479.1385721832067\n",
      "98 452.63169882882966\n",
      "99 427.6886191389216\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(100):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
