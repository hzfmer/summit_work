{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample, resample_poly\n",
    "import struct\n",
    "import imageio\n",
    "import collections\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib2 import Path\n",
    "import pretty_errors\n",
    "from filter_BU import filt_B\n",
    "import my_pyrotd\n",
    "from awp_processing import awp\n",
    "from post_processing.la_habra import *\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.errstate(divide='ignore')\n",
    "#%config InlineBackend.figure_format = 'retina'\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.signal.tf_misfit import plot_tfr, em, pm, tem, tpm, fem, fpm, tfem, tfpm\n",
    "\n",
    "def resize(vel, vel_rec, dt=None):\n",
    "    length = int(len(vel['t']) * vel['dt'] // dt)\n",
    "    length_rec = int(len(vel_rec['t']) * vel_rec['dt'] // dt)\n",
    "    #print(f'Length of time steps = {length}')\n",
    "    if length > len(vel['t']):\n",
    "        print(f\"Upsample may introduce alias. Use larger dt_sample instead.\\n\")\n",
    "        return\n",
    "    for comp in 'XYZ':\n",
    "        if length > length_rec:     \n",
    "            vel[comp] = vel[comp][vel['t'] <= vel_rec['t'][-1]]\n",
    "            vel[comp] = resample(vel[comp], length_rec)\n",
    "            vel_rec[comp] = resample(vel_rec[comp], length_rec)\n",
    "        else:\n",
    "            vel_rec[comp] = vel_rec[comp][vel_rec['t'] <= vel['t'][-1]]\n",
    "            vel_rec[comp] = resample(vel_rec[comp], length)\n",
    "            vel[comp] = resample(vel[comp], length)\n",
    "            \n",
    "   \n",
    "def plot_obspy_tf_misfit(misfit, comps='XYZ', left=0.1, bottom=0.1,\n",
    "                    h_1=0.2, h_2=0.125, h_3=0.2, w_1=0.2, w_2=0.6, w_cb=0.01,\n",
    "                    d_cb=0.0, show=True, plot_args=['k', 'r', 'b'], ylim=0.,\n",
    "                    clim=0., cmap='RdBu_r', fmin=0.15, fmax=5, dpi=300):\n",
    "    from matplotlib.ticker import NullFormatter\n",
    "    figs = []\n",
    "    t = misfit['t']\n",
    "    f = misfit['f']\n",
    "    ntr = len(comps)\n",
    "    for itr, comp in enumerate(comps):\n",
    "        fig = plt.figure(dpi=dpi)\n",
    "        data = misfit[comp]\n",
    "        \n",
    "        # plot signals\n",
    "        ax_sig = fig.add_axes([left + w_1, bottom + h_2 + h_3, w_2, h_1])\n",
    "        ax_sig.plot(t, data['rec'], plot_args[0], label=f'data, max={100 * np.max(data[\"rec\"]):.3f} cm/s')\n",
    "        ax_sig.plot(t, data['syn'], plot_args[1], label=f'syn, max={100 * np.max(data[\"syn\"]):.3f} cm/s')\n",
    "        ax_sig.legend(loc=1, ncol=2)\n",
    "\n",
    "        # plot TEM\n",
    "        if 'tem' in data:\n",
    "            ax_tem = fig.add_axes([left + w_1, bottom + h_1 + h_2 + h_3, w_2, h_2])\n",
    "            ax_tem.plot(t, data['tem'], plot_args[2])\n",
    "\n",
    "        # plot TFEM\n",
    "        if 'tfem' in data:\n",
    "            ax_tfem = fig.add_axes([left + w_1, bottom + h_1 + 2 * h_2 + h_3, w_2,\n",
    "                                    h_3])\n",
    "\n",
    "            img_tfem = ax_tfem.pcolormesh(t, f, data['tfem'], cmap=cmap)\n",
    "            img_tfem.set_rasterized(True)\n",
    "            ax_tfem.set_yscale(\"log\")\n",
    "            ax_tfem.set_ylim(fmin, fmax)\n",
    "\n",
    "        # plot FEM\n",
    "        if 'fem' in data:\n",
    "            ax_fem = fig.add_axes([left, bottom + h_1 + 2 * h_2 + h_3, w_1, h_3])\n",
    "            ax_fem.semilogy(data['fem'], f, plot_args[2])\n",
    "            ax_fem.set_ylim(fmin, fmax)\n",
    "\n",
    "        # plot TPM\n",
    "        if 'tpm' in data:\n",
    "            ax_tpm = fig.add_axes([left + w_1, bottom, w_2, h_2])\n",
    "            ax_tpm.plot(t, data['tpm'], plot_args[2])\n",
    "\n",
    "        # plot TFPM\n",
    "        if 'tfpm' in data:\n",
    "            ax_tfpm = fig.add_axes([left + w_1, bottom + h_2, w_2, h_3])\n",
    "\n",
    "            img_tfpm = ax_tfpm.pcolormesh(t, f, data['tfpm'], cmap=cmap)\n",
    "            img_tfpm.set_rasterized(True)\n",
    "            ax_tfpm.set_yscale(\"log\")\n",
    "            ax_tfpm.set_ylim(f[0], f[-1])\n",
    "\n",
    "        # add colorbars\n",
    "        ax_cb_tfpm = fig.add_axes([left + w_1 + w_2 + d_cb + w_cb, bottom,\n",
    "                                   w_cb, h_2 + h_3])\n",
    "        fig.colorbar(img_tfpm, cax=ax_cb_tfpm)\n",
    "\n",
    "        # plot FPM\n",
    "        if 'fpm' in data:\n",
    "            ax_fpm = fig.add_axes([left, bottom + h_2, w_1, h_3])\n",
    "            ax_fpm.semilogy(data['fpm'], f, plot_args[2])\n",
    "            ax_fpm.set_ylim(fmin, fmax)\n",
    "\n",
    "        # set limits\n",
    "        ylim_sig = np.max([np.abs(data['rec']).max(), np.abs(data['syn']).max()]) * 2\n",
    "        ax_sig.set_ylim(-ylim_sig, ylim_sig)\n",
    "\n",
    "        if ylim == 0.:\n",
    "            ylim = np.max([np.abs(data[key]).max() for key in ['tem', 'tpm', 'fem', 'fpm'] \\\n",
    "                           if key in data]) * 1.1\n",
    "    \n",
    "        ax_tem.set_ylim(-ylim, ylim)\n",
    "        ax_fem.set_xlim(-ylim, ylim)\n",
    "        ax_tpm.set_ylim(-ylim, ylim)\n",
    "        ax_fpm.set_xlim(-ylim, ylim)\n",
    "\n",
    "        ax_sig.set_xlim(t[0], t[-1])\n",
    "        ax_tem.set_xlim(t[0], t[-1])\n",
    "        ax_tpm.set_xlim(t[0], t[-1])\n",
    "\n",
    "        if clim == 0.:\n",
    "            clim = np.max([np.abs(data['tfem']).max(), np.abs(data['tfpm']).max()])\n",
    "\n",
    "        img_tfpm.set_clim(-clim, clim)\n",
    "        img_tfem.set_clim(-clim, clim)\n",
    "\n",
    "        # add text box for EM + PM\n",
    "        textstr = f\"{comp}-component\\nEM = {data['em']: .2f}\\nPM = {data['pm']: .2f}\"\n",
    "        props = dict(boxstyle='round', facecolor='white')\n",
    "        ax_sig.text(-0.3, 0.5, textstr, transform=ax_sig.transAxes,\n",
    "                    verticalalignment='center', horizontalalignment='left',\n",
    "                    bbox=props)\n",
    "\n",
    "        ax_tpm.set_xlabel('time (s)')\n",
    "        ax_fem.set_ylabel('frequency (Hz)')\n",
    "        ax_fpm.set_ylabel('frequency (Hz)')\n",
    "\n",
    "        # add text boxes\n",
    "        props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "        ax_tfem.text(0.95, 0.85, 'TFEM', transform=ax_tfem.transAxes,\n",
    "                     verticalalignment='top', horizontalalignment='right',\n",
    "                     bbox=props)\n",
    "        ax_tfpm.text(0.95, 0.85, 'TFPM', transform=ax_tfpm.transAxes,\n",
    "                     verticalalignment='top', horizontalalignment='right',\n",
    "                     bbox=props)\n",
    "        ax_tem.text(0.95, 0.75, 'TEM', transform=ax_tem.transAxes,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=props)\n",
    "        ax_tpm.text(0.95, 0.75, 'TPM', transform=ax_tpm.transAxes,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=props)\n",
    "        ax_fem.text(0.9, 0.85, 'FEM', transform=ax_fem.transAxes,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=props)\n",
    "        ax_fpm.text(0.9, 0.85, 'FPM', transform=ax_fpm.transAxes,\n",
    "                    verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=props)\n",
    "\n",
    "        # remove axis labels\n",
    "        ax_tfpm.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax_tfem.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax_tem.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax_sig.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax_tfpm.yaxis.set_major_formatter(NullFormatter())\n",
    "        ax_tfem.yaxis.set_major_formatter(NullFormatter())\n",
    "\n",
    "        figs.append(fig)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        if ntr == 1:\n",
    "            return figs[0]\n",
    "        else:\n",
    "            return figs\n",
    "        \n",
    "        \n",
    "def comp_obspy_tf_misfit(model, site_name, dt, comps='XYZ', \n",
    "                         fmin=0.15, fmax=5, nf=128, vel=None, vel_rec=None, plot=False):\n",
    "    if vel is None:\n",
    "        with open('results/vel_syn.pickle', 'rb') as fid:\n",
    "            vel_syn = pickle.load(fid)\n",
    "        vel = vel_syn[model][site_name]\n",
    "        vel_rec = vel_syn[\"rec\"][site_name]\n",
    "        \n",
    "    resize(vel, vel_rec, dt)\n",
    "    res = {}\n",
    "    res['dt'] = dt\n",
    "    res['f'] = np.logspace(np.log10(fmin), np.log10(fmax), nf)\n",
    "    \n",
    "    for comp in comps:\n",
    "        res[comp] = {}\n",
    "        res[comp]['syn'] = vel[comp]\n",
    "        res[comp]['rec'] = vel_rec[comp]\n",
    "        res[comp]['em'] = em(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['pm'] = pm(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['tfem'] = tfem(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['tfpm'] = tfpm(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['tem'] = tem(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['tpm'] = tpm(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['fem'] = fem(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['fpm'] = fpm(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "    res['t'] = np.arange(res[comp]['tem'].shape[-1]) * dt\n",
    "    if plot:\n",
    "        plot_obspy_tf_misfit(res, comps=comps)\n",
    "    return res\n",
    "        \n",
    "    \n",
    "    \n",
    "def comp_obspy_tf_misfits(models, dt, comps='XYZ', fmin=0.15, fmax=5, nf=128):\n",
    "    misfit = {}\n",
    "    with open('results/vel_syn.pickle', 'rb') as fid:\n",
    "        vel_syn = pickle.load(fid)\n",
    "        \n",
    "    for model in models:\n",
    "        misfit[model] = {}\n",
    "        vel = vel_syn[model]\n",
    "        vel_rec = vel_syn['rec']\n",
    "        for site_name in vel_syn[model].keys():\n",
    "            print(f'{model}: {site_name}')\n",
    "            misfit[model][site_name] = comp_obspy_tf_misfit( \\\n",
    "                    model, site_name, dt, comps=comps, fmin=fmin, fmax=fmax, \n",
    "                    nf=nf, vel=vel[site_name], vel_rec=vel_rec[site_name])\n",
    "    return misfit\n",
    "\n",
    "def comp_obspy_tf_misfit_short(model, site_name, dt, comps='XYZ', \n",
    "                         fmin=0.15, fmax=5, nf=128, vel=None, vel_rec=None, plot=False):\n",
    "    if vel is None:\n",
    "        with open('results/vel_syn.pickle', 'rb') as fid:\n",
    "            vel_syn = pickle.load(fid)\n",
    "        vel = vel_syn[model][site_name]\n",
    "        vel_rec = vel_syn[\"rec\"][site_name]\n",
    "        \n",
    "    resize(vel, vel_rec, dt)\n",
    "    res = {}\n",
    "    res['dt'] = dt\n",
    "    res['f'] = np.logspace(np.log10(fmin), np.log10(fmax), nf)\n",
    "    \n",
    "    for comp in comps:\n",
    "        res[comp] = {}\n",
    "        res[comp]['syn'] = vel[comp]\n",
    "        res[comp]['rec'] = vel_rec[comp]\n",
    "        res[comp]['em'] = em(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['pm'] = pm(vel[comp], vel_rec[comp], dt, fmin, fmax, nf)\n",
    "        res[comp]['eg'] = 10 * np.exp(-abs(res[comp]['em']))\n",
    "        res[comp]['pg'] = 10 * (1 - np.abs(res[comp]['pm']))\n",
    "    res['t'] = np.arange(len(res[comp]['syn'])) * dt\n",
    "    return res\n",
    "\n",
    "\n",
    "def comp_obspy_tf_misfits_short(models, dt, comps='XYZ', fmin=0.15, fmax=5, nf=128):\n",
    "    with open('results/vel_syn.pickle', 'rb') as fid:\n",
    "        vel_syn = pickle.load(fid)\n",
    "        \n",
    "    misfit = {}\n",
    "    for model in models:\n",
    "        misfit[model] = {}\n",
    "        vel = vel_syn[model]\n",
    "        vel_rec = vel_syn['rec']\n",
    "        for i, site_name in enumerate(vel_syn[model].keys()):\n",
    "            if i % 50 == 0:\n",
    "                print(f'{model}: {site_name}')\n",
    "            tmp = comp_obspy_tf_misfit_short( \\\n",
    "                    model, site_name, dt, comps=comps, fmin=fmin, fmax=fmax, \n",
    "                    nf=nf, vel=vel[site_name], vel_rec=vel_rec[site_name])\n",
    "            out = []\n",
    "            for i, comp in enumerate(comps):\n",
    "                out.append(tmp[comp]['em'])  \n",
    "                out.append(tmp[comp]['pm'])  \n",
    "            for i, comp in enumerate(comps):\n",
    "                out.append(tmp[comp]['eg'])  \n",
    "                out.append(tmp[comp]['pg'])\n",
    "            misfit[model][site_name] = np.array(out, dtype='float32').reshape(6, 2)\n",
    "    return misfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lon1, lat1, lon2=-117.932587, lat2=33.918633):\n",
    "    lat1, lon1, lat2, lon2 = np.radians((lat1, lon1, lat2, lon2))\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    d = 0.5 - np.cos(dlat) / 2 + np.cos(lat1) * np.cos(lat2)  * (1 - np.cos(dlon)) / 2\n",
    "    return 12742 * np.arcsin(np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(fname):\n",
    "    return  pickle.loads(Path(fname).read_bytes())\n",
    "\n",
    "def write_pickle(data, fname):\n",
    "    with open(fname, 'wb') as fid:\n",
    "        pickle.dump(data, fid, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_topo(fname, mx, my):\n",
    "    \"\"\"Return topog (my, mx)\"\"\"\n",
    "    pad = 8\n",
    "    with open(fname, 'rb') as fout:\n",
    "        mx, my, pad = np.frombuffer(fout.read(12), dtype='int32')\n",
    "        topo = np.frombuffer(fout.read((mx + 2 * pad) * (my + 2 * pad) * 4),\n",
    "                             dtype='float32').reshape(mx + 2 * pad, my + 2 * pad).T\n",
    "        return topo[pad : -pad, pad : -pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9681, 5086, 709]\n"
     ]
    }
   ],
   "source": [
    "# band pass filter\n",
    "lowf, highf = 0.15, 5\n",
    "osc_freqs = np.concatenate((np.linspace(0.1, 10, 100),\n",
    "                        [1/3, 2, 3, 4, 5]))\n",
    "osc_freqs = sorted(osc_freqs)\n",
    "fqs = [2, 3, 4, 5]\n",
    "\n",
    "\n",
    "mx, my = 19440, 14904\n",
    "dh = 8\n",
    "tmax, dt, tskip, wstep, nfile = read_param(\"\")\n",
    "tpad = tmax + 5  # Padding 5 seconds when using bbs preparing\n",
    "nd = 500  # avoid abc boudnary, which is at most 80 * 3 = 240\n",
    "dt = dt * tskip\n",
    "nt = int(tmax / dt)\n",
    "fs = 1 / dt\n",
    "\n",
    "# Topography\n",
    "if \"topography\" not in locals():\n",
    "    topography = read_topo('topography.bin', mx, my)\n",
    "#     topo_grad = np.gradient(topography, dh)\n",
    "#     topo_grad = np.sqrt(topo_grad[0] ** 2 + topo_grad[1] ** 2)\n",
    "    \n",
    "# sites of recordings\n",
    "# url_rec = 'http://hypocenter.usc.edu/bbp/highf/data/2020-08-10-data-processed/'\n",
    "# r = requests.get(url_rec)\n",
    "# rec_sites = re.findall('(?<=\">p-).+(?=\\\\.V2.vel)', r.text)\n",
    "\n",
    "# orig_sites = np.genfromtxt('stat_name_idx.txt', delimiter=\" \", dtype=\"S8, i4, i4\")\n",
    "# seems Fabio doesn't remove \"_\" in site name now\n",
    "if os.path.isfile('results/syn_sites.pickle'):\n",
    "    with open('results/syn_sites.pickle', 'rb') as fid:\n",
    "        syn_sites = pickle.load(fid)\n",
    "else:\n",
    "    syn_sites = [(name.decode('UTF-8').replace('_', ''), ix, iy) for name, ix, iy in orig_sites \\\n",
    "             if nd < ix < mx - nd and nd < iy < my - nd] \n",
    "    with open('results/syn_sites.pickle', 'wb') as fid:\n",
    "        pickle.dump(syn_sites, fid, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Source index \n",
    "if 1:# and 'srcidx' not in locals():\n",
    "#     grids = np.fromfile('surf.grid', dtype='float64').reshape(my, mx, 3)[:, :, :2]\n",
    "#     grids_squeeze = np.reshape(grids, (-1, 2))\n",
    "    nsrcx = nsrcz = 125\n",
    "    src_lonlat = [-117.932587, 33.918633]\n",
    "    src_idx = np.genfromtxt('fault_idx.txt', dtype='int').reshape(nsrcz, nsrcx, 3)\n",
    "    srcidx = [int(x) for x in (np.mean(src_idx, axis=(0, 1)))]  # (ix, iy, iz)\n",
    "    \n",
    "    print(srcidx)\n",
    "    # from scipy import spatial\n",
    "    # kdtree = spatial.cKDTree(grids_squeeze)\n",
    "    # query_idx = np.unravel_index(kdtree.query(src_lonlat)[1], (my, mx))  # (iy, ix)\n",
    "    # srcidx = query_idx[::-1] + (srcidx[-1],)  #(ix, iy, iz)\n",
    "    # srcidx = [4037, 2732, 709]\n",
    "#     print(f'Interpolated source lon/lat: {grids[srcidx[1], srcidx[0]]}\\n', \n",
    "#           f'Close to records? {np.isclose(grids[srcidx[1], srcidx[0]], src_lonlat, atol=5e-5)}')\n",
    "#     del grids\n",
    "\n",
    "site_latlon = np.genfromtxt('la_habra_large_statlist_070120.txt', usecols=[0,1,2,3], dtype=\"S8, f, f, f\")\n",
    "site_dist = {}\n",
    "site_vs30 = {}\n",
    "site_elev = {}\n",
    "site_idx = {}\n",
    "for i in range(len(site_latlon)):\n",
    "    site_name = site_latlon[i][0].decode('UTF-8').replace('_', '')\n",
    "    site_idx[site_name] = (syn_sites[i][1], syn_sites[i][2])\n",
    "    site_dist[site_name] = np.sqrt((srcidx[-1] * dh / 1000) ** 2 +  \\\n",
    "                           distance(site_latlon[i][1], site_latlon[i][2]) ** 2)\n",
    "    site_vs30[site_name] = site_latlon[i][3]\n",
    "    site_elev[site_name] = topography[syn_sites[i][2], syn_sites[i][1]]\n",
    "\n",
    "sorted_site_elev = [(k, v) for k, v in sorted(site_elev.items(), key=lambda x: x[1])]\n",
    "sorted_site_dist = [(k, v) for k, v in sorted(site_dist.items(), key=lambda x: x[1])]\n",
    "\n",
    "\n",
    "  \n",
    "# # VS30 is at the approxmately 5th layer; skip = 4\n",
    "# from scipy.stats import hmean\n",
    "# vs30 = np.fromfile('mesh', dtype='float32', count=mx * my * 3 * 3).reshape(3, my, mx, 3)[:, :, :, 1]\n",
    "# vs30 = hmean(vs30, axis=0)\n",
    "vs = np.fromfile('mesh_large_8m_orig.bin_0', dtype='float32', count=mx * my * 3).reshape(my, mx, 3)[:, :, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_sites' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "ds = []\n",
    "for i in range(len(site_latlon)):\n",
    "    d = {}\n",
    "    site_name = site_latlon[i][0].decode('UTF-8').replace('_', '')\n",
    "    d[\"site_name\"] = site_name \n",
    "    d[\"lon\"] = site_latlon[i][1]\n",
    "    d[\"lat\"] = site_latlon[i][2]\n",
    "    d[\"idx_x\"] = syn_sites[i][1]\n",
    "    d[\"idx_y\"] = syn_sites[i][2]\n",
    "    d[\"vs30\"] = site_latlon[i][3]\n",
    "    d[\"vs\"] = vs[syn_sites[i][2], syn_sites[i][1]]\n",
    "    d[\"elevation\"] = topography[syn_sites[i][2], syn_sites[i][1]]\n",
    "    d[\"rhyp\"] = site_dist[site_name]\n",
    "    ds.append(d)\n",
    "df_sites = pd.DataFrame(ds, index=None)\n",
    "df_sites.set_index('site_name', drop=True, inplace=True)\n",
    "df_sites.sort_values(\"rhyp\", inplace=True)\n",
    "#df_sites.reset_index(drop=False, inplace=True)\n",
    "#df_sites.to_csv(\"results/df_sites.csv\", index=False)\n",
    "\n",
    "# or row.idx_x < srcidx[0]\n",
    "df_sites['west'] = df_sites.apply(lambda row: \"west\" if row.lon < src_lonlat[0] \\\n",
    "                                 else \"east\", axis=1)\n",
    "site_info = df_sites.columns.tolist()\n",
    "%store df_sites\n",
    "df_sites.head()\n",
    "del vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right, bot, top = -118.5, -117.23, 33.6, 34.35\n",
    "\n",
    "labels = {'arias': r'Arias (cm/s)', 'pga': r'PGA (cm/s@+2@+)', 'pgv': r'PGV (cm/s)',\n",
    "          'ener': r'ENER (cm/s@+2@+)', 'dur': 'DUR (s)'}\n",
    "metrics = list(labels.keys())\n",
    "\n",
    "%store -r model_dict\n",
    "model_id = {k: i for i, k in enumerate(model_dict)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_syn = collections.defaultdict(dict)\n",
    "\n",
    "\n",
    "models = ['dhyp0.50_s1485839278_q100f00_orig_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_orig_vs500',\n",
    "          'dhyp1.50_s372823598_q100f00_orig_vs200',\n",
    "          'dhyp1.00_s387100462_q100f00_orig_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s05h005l100_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s05h005l500_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s10h005l500_vs200',\n",
    "          'rec']\n",
    "\n",
    "with open('results/vel_syn.pickle', 'rb') as fid:\n",
    "    vel_syn = pickle.load(fid)\n",
    "\n",
    "\n",
    "# models = ['dhyp0.50_s1485839278_q100f00_s10h005l100_vs200']\n",
    "# for model in models:\n",
    "#     if model in vel_syn.keys():\n",
    "#         continue\n",
    "#     try:\n",
    "#         with open(Path(model, 'vel_sites.pickle'), 'rb') as fid:      \n",
    "#             vel_syn[model] = pickle.load(fid) \n",
    "#             for k in vel_syn[model].keys():  # Each site\n",
    "#                 vel_syn[model][k] = rotate(vel_syn[model][k], -39.9)\n",
    "#                 vel_syn[model][k] = prepare_bbpvel(vel_syn[model][k], tmax)\n",
    "\n",
    "#     except:\n",
    "#         print(\"No model found: \", model)\n",
    "#         with open(f'results/vel_{model}.pickle', 'rb') as fid:\n",
    "#             vel_syn[model] = pickle.load(fid)\n",
    "            \n",
    "# with open(f'results/vel_rec.pickle', 'rb') as fid:\n",
    "#     vel_syn['rec'] = pickle.load(fid)\n",
    "# # for k in vel_syn['rec'].keys():  # Each site\n",
    "# #     vel_syn['rec'][k] = prepare_bbpvel(vel_syn['rec'][k], tmax, shift=vel_syn['rec'][k]['shift'], \n",
    "# #                                        dt=vel_syn['dhyp0.50_s1485839278_q100f00_orig_vs200'][k]['dt'])\n",
    "\n",
    "# with open(Path(\"../la_habra_large_gpu_abc50/topo_q100f08_sh005l100_vs30_vs500\", 'vel_sites.pickle'), 'rb') as fid:      \n",
    "#     tmp = pickle.load(fid) \n",
    "#     for k in tmp.keys():  # Each site\n",
    "#         tmp[k] = rotate(tmp[k], -39.9)\n",
    "#         tmp[k] = prepare_bbpvel(tmp[k], tmax)\n",
    "\n",
    "# vel_syn['topo_q100f08_sh005l100_vs30_vs500'] = tmp\n",
    "\n",
    "# with open('results/vel_syn.pickle', 'wb') as fid:\n",
    "#     pickle.dump(vel_syn, fid, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read bbp-format recordings\n",
    "\n",
    "# def read_bbp(texts):\n",
    "#     res = {}\n",
    "#     data = np.genfromtxt(texts)\n",
    "#     res['t'] = data[:, 0]\n",
    "#     res['dt'] = data[1, 0] - data[0, 0]\n",
    "#     for i, comp in enumerate('YXZ', 1):\n",
    "#         res[comp] = dat[:, i] / 100  # cm/s2 --> m/s2\n",
    "#     return res\n",
    "\n",
    "# vel_rec = collections.defaultdict(dict)\n",
    "# for i, isite in enumerate(orig_sites):\n",
    "#     site_name = isite[0].decode('UTF-8')\n",
    "#     r = requests.get(f'{url_rec}/p-{site_name}.V2.vel.bbp')\n",
    "#     if r.status_code != 200:\n",
    "#         print(f\"the site {site_name} not found on the server\")\n",
    "#         continue\n",
    "#     vel_rec[site_name.replace('_', '')] = read_bbp(r.text.split('\\n'))\n",
    "# vel_syn['rec'] = vel_rec\n",
    "\n",
    "# # End reading\n",
    "\n",
    "\n",
    "# with open('results/vel_syn.pickle', 'wb') as fid:\n",
    "#     pickle.dump(vel_syn, fid, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500'\n",
    "with open(Path(f\"../la_habra_large_gpu_abc50/{model}\", 'vel_sites.pickle'), 'rb') as fid:      \n",
    "    tmp = pickle.load(fid) \n",
    "    for k in tmp.keys():  # Each site\n",
    "        tmp[k] = rotate(tmp[k], -39.9)\n",
    "        tmp[k] = prepare_bbpvel(tmp[k], tmax)\n",
    "\n",
    "vel_syn[model] = tmp\n",
    "with open('results/vel_syn.pickle', 'wb') as fid:\n",
    "    pickle.dump(vel_syn, fid, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models queried!\n",
      "['topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500']\n",
      "\n",
      "Gathering psa_syn for CE12919, 0/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13066, 1/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13067, 2/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13068, 3/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13069, 4/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13079, 5/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13080, 6/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13096, 7/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13098, 8/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13099, 9/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13100, 10/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13123, 11/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13160, 12/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13162, 13/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13174, 14/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13197, 15/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13215, 16/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13220, 17/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13441, 18/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13726, 19/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13849, 20/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13873, 21/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13875, 22/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13877, 23/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13878, 24/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13879, 25/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13880, 26/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13881, 27/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13882, 28/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13883, 29/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13884, 30/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13885, 31/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13886, 32/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13887, 33/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13888, 34/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13889, 35/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13890, 36/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13892, 37/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13893, 38/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13894, 39/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13913, 40/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13914, 41/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13915, 42/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13916, 43/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13918, 44/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13921, 45/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13924, 46/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE13927, 47/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14001, 48/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14002, 49/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14004, 50/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14005, 51/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14006, 52/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14007, 53/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14017, 54/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14026, 55/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14027, 56/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14028, 57/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14036, 58/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14041, 59/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14043, 60/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14044, 61/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14058, 62/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14059, 63/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14060, 64/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14125, 65/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14175, 66/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14241, 67/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14242, 68/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14368, 69/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14400, 70/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14403, 71/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14560, 72/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14767, 73/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14787, 74/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14820, 75/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14821, 76/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14822, 77/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14825, 78/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14827, 79/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14828, 80/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14829, 81/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14830, 82/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14834, 83/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14840, 84/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14844, 85/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14846, 86/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14847, 87/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14869, 88/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14871, 89/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14872, 90/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14934, 91/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14935, 92/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14936, 93/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14937, 94/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE14988, 95/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23024, 96/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23049, 97/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23056, 98/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23057, 99/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23075, 100/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23077, 101/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23084, 102/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23089, 103/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23090, 104/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23091, 105/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23138, 106/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23163, 107/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23164, 108/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23173, 109/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23177, 110/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23178, 111/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23179, 112/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23292, 113/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23327, 114/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23417, 115/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23525, 116/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23542, 117/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23773, 118/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23774, 119/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23780, 120/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23836, 121/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23842, 122/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23843, 123/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23895, 124/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23897, 125/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23898, 126/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23899, 127/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23938, 128/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23939, 129/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23940, 130/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE23958, 131/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24010, 132/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24020, 133/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24022, 134/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24023, 135/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24025, 136/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24029, 137/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24030, 138/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24033, 139/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24034, 140/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24039, 141/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24040, 142/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24109, 143/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24110, 144/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24114, 145/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24157, 146/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24289, 147/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24399, 148/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24461, 149/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24592, 150/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24611, 151/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24612, 152/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24691, 153/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24806, 154/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24811, 155/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24814, 156/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24833, 157/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24838, 158/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24839, 159/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24841, 160/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24850, 161/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24851, 162/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24852, 163/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24853, 164/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24941, 165/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24945, 166/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24977, 167/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24980, 168/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24982, 169/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24983, 170/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24984, 171/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CE24987, 172/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIBBS, 173/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIBFS, 174/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIBHP, 175/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIBRE, 176/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICAC, 177/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICFS, 178/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICFT, 179/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICHN, 180/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICJM, 181/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICLT, 182/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CICRN, 183/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIDLA, 184/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIFON, 185/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIFUL, 186/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIGSA, 187/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIGVR, 188/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIHLN, 189/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIIPT, 190/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIKIK, 191/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILAF, 192/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILBW1, 193/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILCG, 194/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILGB, 195/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILLS, 196/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILPC, 197/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILTP, 198/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CILUG, 199/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIMLS, 200/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIMWC, 201/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CINOT, 202/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIOGC, 203/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIOLI, 204/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIPDR, 205/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIPDU, 206/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIPER, 207/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIPLS, 208/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIPSR, 209/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0000, 210/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0001, 211/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0002, 212/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0005, 213/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0009, 214/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0013, 215/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0014, 216/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0016, 217/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0018, 218/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0020, 219/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0021, 220/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0022, 221/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0023, 222/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0026, 223/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0028, 224/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0029, 225/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0034, 226/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0035, 227/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0038, 228/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0041, 229/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0042, 230/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0046, 231/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0048, 232/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0049, 233/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0057, 234/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0063, 235/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0066, 236/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0067, 237/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIQ0074, 238/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIRIN, 239/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIRIO, 240/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIRSS, 241/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIRUS, 242/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIRVR, 243/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISAN, 244/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISBPX, 245/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISDD, 246/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISMF2, 247/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISOF, 248/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISRN, 249/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISTG, 250/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISTS, 251/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CISVD, 252/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CITA2, 253/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIUSC, 254/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIWLT, 255/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIWSS, 256/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for CIWTT2, 257/259\n",
      ": topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Gathering psa_syn for NP707, 258/259\n",
      "Appending new models for psa00vs30erf100_cap_vs500\n"
     ]
    }
   ],
   "source": [
    "psa_syn = read_pickle('results/psa_syn.pickle')\n",
    "\n",
    "# models = ['dhyp0.50_s1485839278_q100f00_orig_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_orig_vs500',\n",
    "#           'dhyp1.50_s372823598_q100f00_orig_vs200',\n",
    "#           'dhyp1.00_s387100462_q100f00_orig_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s05h005l100_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s05h005l500_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s10h005l500_vs200',\n",
    "#           'rec',\n",
    "#          ]\n",
    "models = [\n",
    "    #'topo_q100f08_sh005l100_vs30_vs500',\n",
    "#     'topo_q50t07f08_vs30_vs500',\n",
    "#     'topo_q50f08_vs30erf100_vs500',\n",
    "#     'topo_q50f08_vs30erf200_vs500',\n",
    "#     'topo_q100f06_1000vs30erf100_cap_vs500',\n",
    "#     'topo_q50f08_orig_vs500',\n",
    "#     'topo_q100f06_orig_vs500',\n",
    "#     'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500',\n",
    "    'topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500',\n",
    "]\n",
    "psa_syn = pick_psa(mx, my, models, force_update=True,\n",
    "                   osc_freqs=osc_freqs, syn_sites=syn_sites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf_misfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE12919\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE14004\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE23075\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE24592\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CIMLS\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CISTG\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE12919\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE14004\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE23075\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE24592\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CIMLS\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CISTG\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE12919\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE14004\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE23075\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE24592\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CIMLS\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CISTG\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE12919\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE14004\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE23075\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE24592\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CIMLS\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CISTG\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE12919\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE14004\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE23075\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CE24592\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CIMLS\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500: CISTG\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "dict_keys(['dhyp0.50_s1485839278_q100f00_orig_vs200', 'dhyp0.50_s1485839278_q100f00_orig_vs500', 'dhyp1.50_s372823598_q100f00_orig_vs200', 'dhyp1.00_s387100462_q100f00_orig_vs200', 'dhyp0.50_s1485839278_q100f00_s05h005l100_vs200', 'dhyp0.50_s1485839278_q100f00_s10h005l500_vs200', 'dhyp0.50_s1485839278_q100f00_s05h005l500_vs200', 'q100f06_orig_vs500', 'q100f00_orig_vs500', 'topo_q100f00_s05h005l100_vs500', 'rec', 'topo_q50f06_s05h005l100_vs500', 'topo_q50f08_s05h005l100_vs500', 'topo_q100f00_orig_vs500', 'topo_q100f06_s05h005l100_vs500', 'topo_q100f08_orig_vs500', 'topo_q100f06_vs30_vs500', 'topo_q50f08_vs30_vs500', 'dhyp0.50_s1485839278_q100f00_s10h005l100_vs200', 'topo_q100f08_sh005l100_vs30_vs500', 'topo_q100f08_sh005l500_vs30_vs500', 'topo_q50t04f08_vs30_vs500', 'topo_q50t07f08_vs30_vs500', 'topo_q50f08_vs30erf100_vs500', 'topo_q50f08_vs30erf200_vs500', 'topo_q100f06_orig_cap_vs500', 'topo_q100f06_1000vs30erf100_cap_vs500', 'topo_q50f08_orig_vs500', 'topo_q100f06_orig_vs500', 'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500', 'topo_q100f06_sh005l1000_cap_vs500', 'topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500'])\n"
     ]
    }
   ],
   "source": [
    "# Run this one\n",
    "# EM/PM/EG/PG only tf_misfit\n",
    "\n",
    "dt = 0.04\n",
    "try:\n",
    "    tf_misfit = pickle.loads(Path('results/tf_misfit.pickle').read_bytes())\n",
    "except:\n",
    "    tf_misfit = {}\n",
    "    \n",
    "models = ['dhyp0.50_s1485839278_q100f00_orig_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_orig_vs500',\n",
    "          'dhyp1.50_s372823598_q100f00_orig_vs200',\n",
    "          'dhyp1.00_s387100462_q100f00_orig_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s05h005l100_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s05h005l500_vs200',\n",
    "          'dhyp0.50_s1485839278_q100f00_s10h005l500_vs200']\n",
    "models = [\n",
    "    #'topo_q50f08_s05h005l100_vs500',\n",
    "    #'topo_q100f00_orig_vs500',\n",
    "    #'topo_q100f06_s05h005l100_vs500',\n",
    "#     'topo_q100f08_sh005l100_vs30_vs500',\n",
    "#     'topo_q100f08_sh005l500_vs30_vs500',\n",
    "#     'topo_q50t07f08_vs30_vs500',\n",
    "    #'dhyp0.50_s1485839278_q100f00_s10h005l100_vs200',\n",
    "#     'topo_q50f08_vs30erf100_vs500',\n",
    "#     'topo_q50f08_vs30erf200_vs500',\n",
    "#     'topo_q100f06_1000vs30erf100_cap_vs500',\n",
    "#     'topo_q50f08_orig_vs500',\n",
    "#     'topo_q100f06_orig_vs500',\n",
    "#     'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500',\n",
    "    'topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500',\n",
    "]\n",
    "tmp = {}\n",
    "for f in [(0.15, 2.5), (0.15, 5), (2.5, 5), (0.15, 1), (0.15, 4)]:\n",
    "    if f not in tf_misfit:\n",
    "        tf_misfit[f] = {}\n",
    "#     tf_misfit[f].pop('topo_q50t07f08_vs30_vs500')\n",
    "    models = [model for model in models if model not in tf_misfit[f]]\n",
    "    tmp = comp_obspy_tf_misfits_short(models, dt, fmin=f[0], fmax=f[1])\n",
    "    for model in models:\n",
    "        print(model)\n",
    "        tf_misfit[f][model] = tmp[model]\n",
    "print(tf_misfit[(0.15, 2.5)].keys())\n",
    "\n",
    "\n",
    "# # force rec tf_misfits\n",
    "# rec_tf_misfit = np.zeros((6, 2))\n",
    "# rec_tf_misfit[3:,:] = 10.\n",
    "# for f in tf_misfit.keys():\n",
    "#     tf_misfit[f]['rec'] = {}\n",
    "#     for site_name in tf_misfit[f][models[0]].keys():\n",
    "#         tf_misfit[f]['rec'][site_name] = rec_tf_misfit.copy()\n",
    "        \n",
    "with open('results/tf_misfit.pickle', 'wb') as fid:\n",
    "    pickle.dump(tf_misfit, fid, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics & GOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frequency band = (0.15, 0) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Processing frequency band = (0.15, 1) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Processing frequency band = (0.15, 2.5) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Processing frequency band = (0.15, 4) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Processing frequency band = (0.15, 5) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Processing frequency band = (2.5, 5) Hz\n",
      "topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500\n",
      "Done (0.15, 0)Hz\n",
      "Done (0.15, 1)Hz\n",
      "Done (0.15, 2.5)Hz\n",
      "Done (0.15, 4)Hz\n",
      "Done (0.15, 5)Hz\n",
      "Done (2.5, 5)Hz\n"
     ]
    }
   ],
   "source": [
    "# models = ['dhyp0.50_s1485839278_q100f00_orig_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_orig_vs500',\n",
    "#           'dhyp1.50_s372823598_q100f00_orig_vs200',\n",
    "#           'dhyp1.00_s387100462_q100f00_orig_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s05h005l100_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s05h005l500_vs200',\n",
    "#           'dhyp0.50_s1485839278_q100f00_s10h005l500_vs200',\n",
    "#          ]\n",
    "# models = [\n",
    "#     'topo_q50f08_s05h005l100_vs500',\n",
    "#     'topo_q100f00_orig_vs500',\n",
    "#     'topo_q100f06_s05h005l100_vs500',\n",
    "# ]\n",
    "models = [\n",
    "#     'topo_q100f08_sh005l100_vs30_vs500',\n",
    "#     'topo_q100f08_sh005l500_vs30_vs500',\n",
    "#     'topo_q50t07f08_vs30_vs500',\n",
    "#     'topo_q50f08_vs30erf100_vs500',\n",
    "#     'topo_q50f08_vs30erf200_vs500',\n",
    "#     'topo_q100f06_cap_vs500',\n",
    "#     'topo_q100f06_1000vs30erf100_cap_vs500',\n",
    "#     'topo_q50f08_orig_vs500',\n",
    "#     'topo_q100f06_orig_vs500',\n",
    "#      'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500',\n",
    "    'topo_q100f06_sh005l1000_1000vs30erf100_cap_vs500'\n",
    "]\n",
    "\n",
    "comp_metrics(models, vel_syn, lowcut=0.15, highcut=[0, 1, 2.5, 4, 5],\n",
    "             tmax=tmax, force_update=1, save=True) \n",
    "comp_metrics(models, vel_syn, lowcut=2.5, highcut=[5], tmax=tmax,\n",
    "             force_update=1, save=True)  \n",
    "\n",
    "met = pickle.loads(Path('results/metrics.pickle').read_bytes())\n",
    "# models = list(met[(0.15, 1)].keys())\n",
    "\n",
    "gof = comp_GOF([0, 1, 2.5, 4, 5, (2.5, 5)] , models, vs=site_vs30, \n",
    "    syn_sites=syn_sites, topography=topography, sx=srcidx[0], sy=srcidx[1],\n",
    "        sz=srcidx[2], dh=0.008)\n",
    "\n",
    "\n",
    "gof = pickle.loads(Path('results/gof.pickle').read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge previous results if not present\n",
    "if 0:\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/vel_syn.pickle\")\n",
    "    vel = pickle.loads(Path('results/vel_syn.pickle').read_bytes())\n",
    "    if model not in vel:\n",
    "        vel[model] = tmp[model]\n",
    "    write_pickle(vel, 'results/vel_syn.pickle')\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/psa_syn.pickle\")\n",
    "    psa = pickle.loads(Path('results/psa_syn.pickle').read_bytes())\n",
    "    for model in tmp.keys():\n",
    "        if model not in psa:\n",
    "            psa[model] = tmp[model]\n",
    "    write_pickle(psa, 'results/psa_syn.pickle')\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/psax_syn.pickle\")\n",
    "    psa = pickle.loads(Path('results/psax_syn.pickle').read_bytes())\n",
    "    for model in tmp.keys():\n",
    "        if model not in psa:\n",
    "            psa[model] = tmp[model]\n",
    "    write_pickle(psa, 'results/psax_syn.pickle')\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/psay_syn.pickle\")\n",
    "    psa = pickle.loads(Path('results/psay_syn.pickle').read_bytes())\n",
    "    for model in tmp.keys():\n",
    "        if model not in psa:\n",
    "            psa[model] = tmp[model]\n",
    "    write_pickle(psa, 'results/psay_syn.pickle')\n",
    "\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/gof.pickle\")\n",
    "    gof = pickle.loads(Path('results/gof.pickle').read_bytes())\n",
    "    for f in tmp.keys():\n",
    "        for model in tmp[f].keys():\n",
    "            if f in gof and model not in gof[f]:\n",
    "                gof[f][model] = tmp[f][model]\n",
    "    write_pickle(gof, 'results/gof.pickle')\n",
    "\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/metrics.pickle\")\n",
    "    met = pickle.loads(Path('results/metrics.pickle').read_bytes())\n",
    "    for f in tmp.keys():\n",
    "        for model in tmp[f].keys():\n",
    "            if f in met and model not in met[f]:\n",
    "                met[f][model] = tmp[f][model]\n",
    "    write_pickle(met, 'results/metrics.pickle')\n",
    "\n",
    "    tmp = read_pickle(\"../la_habra_large_gpu_abc50/results/tf_misfit.pickle\")\n",
    "    tf_misfit = pickle.loads(Path('results/tf_misfit.pickle').read_bytes())\n",
    "    for f in tmp.keys():\n",
    "        for model in tmp[f].keys():\n",
    "            if f in tf_misfit and model not in tf_misfit[f]:\n",
    "                tf_misfit[f][model] = tmp[f][model]\n",
    "    write_pickle(tf_misfit, 'results/tf_misfit.pickle')\n",
    "\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single tf_misfit for 0.15 - 5 Hz, with all components, fem, fpm ...\n",
    "\n",
    "\n",
    "# fmin, fmax = 0.15, 5\n",
    "# models = ['dhyp0.50_s1485839278_q100f00_orig_vs200']\n",
    "# obspy_tf_misfit = pickle.loads(Path('results/obspy_tf_misfit.pickle').read_bytes())\n",
    "\n",
    "# # if os.path.isfile('results/obspy_tf_misfit.pickle'):\n",
    "# #     obspy_tf_misfit = pickle.load(open('results/obspy_tf_misfit.pickle', 'rb'))\n",
    "# # else:\n",
    "# dt = 0.04\n",
    "# for model in models:\n",
    "#     if model not in obspy_tf_misfit:\n",
    "#         obspy_tf_misfit[model] = comp_obspy_tf_misfits([model], dt).pop(model)\n",
    "\n",
    "# #     with open('results/obspy_tf_misfit.pickle', 'wb') as fid:\n",
    "# #         pickle.dump(obspy_tf_misfit, fid, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    model_from = 'topo_q100f06_sh005l1000_cap_vs500'\n",
    "    model_to = 'topo_q100f06_sh005l100_1000vs30erf100_cap_vs500'\n",
    "#     vel_syn = read_pickle('results/vel_syn.pickle')\n",
    "#     psa_syn = read_pickle('results/psa_syn.pickle')\n",
    "#     psax_syn = read_pickle('results/psax_syn.pickle')\n",
    "#     psay_syn = read_pickle('results/psay_syn.pickle')\n",
    "#     gof = read_pickle('results/gof.pickle')\n",
    "#     met = read_pickle('results/metrics.pickle')\n",
    "    tf_misfit = read_pickle('results/tf_misfit.pickle')\n",
    "\n",
    "#     vel_syn[model_to] = vel_syn.pop(model_from)\n",
    "#     psa_syn[model_to] = psa_syn.pop(model_from)\n",
    "#     psax_syn[model_to] = psax_syn.pop(model_from)\n",
    "#     psay_syn[model_to] = psay_syn.pop(model_from)\n",
    "\n",
    "#     for f in met:\n",
    "#         met[f][model_to] = met[f].pop(model_from)\n",
    "#         gof[f][model_to] = gof[f].pop(model_from)\n",
    "#     for f in tf_misfit:\n",
    "#         tf_misfit[f][model_to] = tf_misfit[f].pop(model_from)\n",
    "    \n",
    "#     for f in met:\n",
    "#         met[f].pop(model_from)\n",
    "#         gof[f].pop(model_from)\n",
    "    for f in tf_misfit:\n",
    "        tf_misfit[f].pop(model_from)\n",
    "\n",
    "#     write_pickle(vel_syn, 'results/vel_syn.pickle')\n",
    "#     write_pickle(psa_syn, 'results/psa_syn.pickle')\n",
    "#     write_pickle(psax_syn, 'results/psax_syn.pickle')\n",
    "#     write_pickle(psay_syn, 'results/psay_syn.pickle')\n",
    "#     write_pickle(gof, 'results/gof.pickle')\n",
    "#     write_pickle(met, 'results/metrics.pickle')\n",
    "    write_pickle(tf_misfit, 'results/tf_misfit.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# Construct the DataFrame from met and gof\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "met = pickle.loads(Path('results/metrics.pickle').read_bytes())\n",
    "gof = pickle.loads(Path('results/gof.pickle').read_bytes())\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (f, model, site_name) : met[f][model][site_name]\n",
    "             for f in sorted(met.keys())\n",
    "             for model in met[f]\n",
    "             for site_name in met[f][model].keys()\n",
    "    },\n",
    "    orient='index')\n",
    "df = df.sort_index().sort_index(axis=1).unstack(0).unstack(0)\n",
    "\n",
    "df_gof = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        (f, model, site_name) : gof[f][model][site_name]\n",
    "             for f in sorted(gof.keys())\n",
    "             for model in gof[f]\n",
    "             for site_name in gof[f][model].keys()\n",
    "    },\n",
    "    orient='index')\n",
    "df_gof = df_gof.sort_index().sort_index(axis=1).unstack(0).unstack(0)\n",
    "df_gof.drop(['rhypo', 'vs', 'elev'], axis=1, level=0, inplace=True)\n",
    "\n",
    "\n",
    "# psa\n",
    "psa = pickle.loads(Path('results/psa_syn.pickle').read_bytes())\n",
    "freqs = pd.Series([1,2,3,3.5], name='freq')  # frequencies of PSA to query\n",
    "\n",
    "index = pd.MultiIndex.from_product([\n",
    "    ['psa'],\n",
    "    freqs,\n",
    "    df.columns.unique(2),\n",
    "], names=df.columns.names)\n",
    "df_psa = pd.DataFrame(index=df.index, columns=index)\n",
    "\n",
    "for model in df_psa.columns.unique(2):  # model label\n",
    "    osc_freqs = psa[model][df.index[0]].osc_freq\n",
    "    for freq in df_psa.columns.unique(1):  # freq label\n",
    "        idx_f = np.searchsorted(osc_freqs, freq)\n",
    "        for site_name in df_psa.index:\n",
    "            df_psa.loc[site_name, idx['psa', freq, model]] = \\\n",
    "                       psa[model][site_name].spec_accel[idx_f]\n",
    "    \n",
    "    \n",
    "df = df.join(df_gof).join(df_psa)\n",
    "\n",
    "# # Append site information from df_sites\n",
    "# tmp = df_sites.copy()\n",
    "# df[tmp.columns] = tmp\n",
    "\n",
    "\n",
    "# # Sort by rhyp\n",
    "# df.sort_values('rhyp', axis=0, inplace=True)\n",
    "# df.sort_index(key = lambda x : df_sites.loc[x]['rhyp'], inplace=True)\n",
    "\n",
    "\n",
    "# Rename column levels\n",
    "df.rename_axis([\"metric\", \"freq\", \"model\"], axis=1, inplace=True)\n",
    "df.head(2)\n",
    "\n",
    "\n",
    "# Write to disk\n",
    "%store df\n",
    "write_pickle(df, \"results/df.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
